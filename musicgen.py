# -*- coding: utf-8 -*-
"""MusicGen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dZ07Jm8-UVsGMQraWo4Cx_PK35z5CknP
"""

!pip install -U git+https://git@github.com/facebookresearch/audiocraft#egg=audiocraft

from audiocraft.models import MusicGen
from audiocraft.models import MultiBandDiffusion

USE_DIFFUSION_DECODER = False
# Using small model, better results would be obtained with `medium` or `large`.
model = MusicGen.get_pretrained('facebook/musicgen-small')
if USE_DIFFUSION_DECODER:
    mbd = MultiBandDiffusion.get_mbd_musicgen()

"""Next, let us configure the generation parameters. Specifically, you can control the following:

    use_sampling (bool, optional): use sampling if True, else do argmax decoding. Defaults to True.
    top_k (int, optional): top_k used for sampling. Defaults to 250.
    top_p (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.
    temperature (float, optional): softmax temperature parameter. Defaults to 1.0.
    duration (float, optional): duration of the generated waveform. Defaults to 30.0.
    cfg_coef (float, optional): coefficient used for classifier free guidance. Defaults to 3.0.

"""

#Use default parameters

model.set_generation_params(
    use_sampling=True,
    top_k=250,
    duration=30
)

"""Next, we can go ahead and start generating music using one of the following modes:

    Unconditional samples using model.generate_unconditional
    Music continuation using model.generate_continuation
    Text-conditional samples using model.generate
    Melody-conditional samples using model.generate_with_chroma

Music Continuation
"""

import math
import torchaudio
import torch
from audiocraft.utils.notebook import display_audio

def get_bip_bip(bip_duration=0.125, frequency=440,
                duration=0.5, sample_rate=32000, device="cuda"):
    """Generates a series of bip bip at the given frequency."""
    t = torch.arange(
        int(duration * sample_rate), device="cuda", dtype=torch.float) / sample_rate
    wav = torch.cos(2 * math.pi * 440 * t)[None]
    tp = (t % (2 * bip_duration)) / (2 * bip_duration)
    envelope = (tp >= 0.5).float()
    return wav * envelope

# Here we use a synthetic signal to prompt both the tonality and the BPM
# of the generated audio.

import torch
import math
from audiocraft.utils.notebook import display_audio

def get_bip_bip(bip_duration=0.125, frequency=440, duration=0.5, sample_rate=32000, device="cuda"):
    """Generates a series of bip bip at the given frequency."""
    t = torch.arange(int(duration * sample_rate), device="cuda", dtype=torch.float) / sample_rate
    #wav = torch.cos(2 * math.pi * 440 * t)[None],
    wav = torch.cos(2 * math.pi * frequency * t).unsqueeze(0)
    tp = (t % (2 * bip_duration)) / (2 * bip_duration),
    envelope = (tp[0] >= 0.5).float()
    #envelope = torch.round((tp[0]>= 0.5).float())
    return wav * envelope



res = model.generate_continuation(
    get_bip_bip(0.125).expand(2, -1, -1),
    32000, ['Jazz jazz and only jazz',
            'Heartful EDM with beautiful synths and chords'],
    progress=True)
display_audio(res, 32000)

# You can also use any audio from a file. Make sure to trim the file if it is too long!
prompt_waveform, prompt_sr = torchaudio.load("../assets/bach.mp3")
prompt_duration = 2
prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]
output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, progress=True, return_tokens=True)
display_audio(output[0], sample_rate=32000)
if USE_DIFFUSION_DECODER:
    out_diffusion = mbd.tokens_to_wav(output[1])
    display_audio(out_diffusion, sample_rate=32000)

"""Text-conditional Generation"""

from audiocraft.utils.notebook import display_audio

output = model.generate(
    descriptions=[
        #'80s pop track with bassy drums and synth',
        #'90s rock song with loud guitars and heavy drums',
        #'Progressive rock drum and bass solo',
        #'Punk Rock song with loud drum and power guitar',
        #'Bluesy guitar instrumental with soulful licks and a driving rhythm section',
        #'Jazz Funk song with slap bass and powerful saxophone',
        'drum and bass beat with intense percussions',
        'drum and bass beat with intense percussions',
        'drum and bass beat with intense percussions',
        'drum and bass beat with intense percussions'
    ],
    progress=True, return_tokens=True
)
display_audio(output[0], sample_rate=32000)
if USE_DIFFUSION_DECODER:
    out_diffusion = mbd.tokens_to_wav(output[1])
    display_audio(out_diffusion, sample_rate=32000)

"""Melody-conditional Generation"""

import torchaudio
from audiocraft.utils.notebook import display_audio

model = MusicGen.get_pretrained('facebook/musicgen-melody')
model.set_generation_params(duration=8)

melody_waveform, sr = torchaudio.load("../assets/bach.mp3")
melody_waveform = melody_waveform.unsqueeze(0).repeat(2, 1, 1)
output = model.generate_with_chroma(
    descriptions=[
        '80s pop track with bassy drums and synth',
        '90s rock song with loud guitars and heavy drums',
    ],
    melody_wavs=melody_waveform,
    melody_sample_rate=sr,
    progress=True, return_tokens=True
)
display_audio(output[0], sample_rate=32000)
if USE_DIFFUSION_DECODER:
    out_diffusion = mbd.tokens_to_wav(output[1])
    display_audio(out_diffusion, sample_rate=32000)