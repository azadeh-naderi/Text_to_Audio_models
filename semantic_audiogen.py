# -*- coding: utf-8 -*-
"""Semantic_audioGen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-JsKTJvgx4br5P_K8_DiFL54yqXFDJVf
"""

import pandas as pd
import csv
import numpy as np
import requests
import scipy
from scipy.signal import lfilter
import matplotlib.pyplot as plt

!pip install openl3
import openl3
import soundfile as sf

# Define the URL of the CSV file
csv_url = 'https://raw.githubusercontent.com/azadehn/AudioGen/main/audioGen_dataset.csv'

# Read the CSV file from the provided URL
df = pd.read_csv(csv_url)

import os
import zipfile


def load_audio_data(row):
    # Local file paths for the zip files
    zip_file_paths = [
        '/content/1_1000.zip',
        '/content/1001_2000.zip'
    ]

    # Create a temporary directory to extract audio files
    temp_dir = '/content/temp_audio'
    os.makedirs(temp_dir, exist_ok=True)

    audio_files = []  # To store loaded audio data

    for zip_path in zip_file_paths:
        # Extract the zip file
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)

        # Get the filename from the row (assuming it matches the audio file in the zip)
    filename = row["filename"]

        # Load the audio file from the extracted location
    audio_path = os.path.join(temp_dir, filename)
    y, sr = sf.read(audio_path)

    return y, sr  # Return loaded audio data

def comprehensive_matrix(df):

    # Initialize empty list to store feature vectors
    features = []

    # Function to extract features from a single row
    #def extract_features(row):
    for index, row in df.iterrows():
        y, sr = load_audio_data(row)
        emb, ts= openl3.get_audio_embedding(y, sr)

        emb_mean = np.mean(emb, axis=1)
        emb_variance = np.var(emb, axis=1)
        #emb_deltas = np.diff(emb, n=1, axis=1)
        #delta_mean = np.mean(emb_deltas, axis=1)
        #emb_delta_deltas = np.diff(emb, n=2, axis=1)
        #delta_delta_mean = np.mean(emb_delta_deltas, axis=1)

        # Append the results to the respective lists
        feature_vector = np.concatenate((emb_mean, emb_variance))

        features.append(feature_vector)

    # Convert the lists of feature vectors to a feature matrix
    comprehensive_matrix = np.array(features)

    return comprehensive_matrix


# Call the function
comprehensive_matrix = comprehensive_matrix(df)


# Print the matrix
print("Comprehensive Matrix:")
print(comprehensive_matrix)


print(comprehensive_matrix.shape)


saved_matrix = pd.DataFrame(comprehensive_matrix)
saved_matrix.to_csv('comprehensive_matrix.csv', index=False)

from google.colab import files

# Provide the file name you want to download
files.download('comprehensive_matrix.csv')

!pip install scikit-learn
from sklearn.decomposition import PCA

def scree_plot(comprehensive_matrix, num_components=None):

    # Perform PCA
    pca = PCA()
    pca.fit(comprehensive_matrix)

    explained_variace = np.cumsum(pca.explained_variance_ratio_)

    if num_components is not None:
        explained_variace = explained_variace[:num_components]

    # Plot the scree plot
    plt.plot(range(1, len(explained_variace) + 1), explained_variace, marker='o', linestyle='-')
    plt.xlabel('Principal Component Number')
    plt.ylabel('Eigenvalue')
    plt.title('Scree Plot')
    plt.grid()
    plt.show()


# To plot all components:
scree_plot(comprehensive_matrix)

def pca(comprehensive_matrix, num_components=None):

    # Initialize PCA
    pca = PCA(n_components=num_components,whiten = True)

    # Fit the PCA model to the data and transform the data
    reduced_features = pca.fit_transform(comprehensive_matrix)

    return reduced_features


# Call the function to run PCA on comprehensive matrix
reduced_matrix = pca(comprehensive_matrix, num_components=40)

# Print the matrix
print("Reduced Matrix:")
print(reduced_matrix)

reduced_matrix.shape

def total_variance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    tv = np.trace(np.cov(reduced_matrix[df['category'].isin(class_names)].T))

    return tv

class_name = ["dog", "rain"]
result = total_variance(df, reduced_matrix, class_name)
print(result)

def avg_pairwise_distance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    pdist = scipy.spatial.distance.pdist(reduced_matrix[df['category'].isin(class_names)])
    avg_pdist = np.mean(pdist)

    return avg_pdist

class_name = ["dog", "rain"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(result)

def generalized_variance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    gv = np.linalg.det(np.cov(reduced_matrix[df['category'].isin(class_names)].T))

    return gv

class_name = ["dog", "rain"]
result = generalized_variance(df, reduced_matrix, class_name)
print(result)

import scipy.spatial.distance

names = ['dog', 'rooster', 'pig', 'cow', 'frog', 'cat', 'hen', 'insects', 'sheep', 'crow',
         'rain', 'sea_waves', 'crackling_fire', 'crickets', 'chirping_birds', 'water_drops', 'wind', 'pouring_water', 'toilet_flush', 'thunderstorm',
         'crying_baby', 'sneezing', 'clapping', 'breathing', 'coughing', 'footsteps', 'laughing', 'brushing_teeth', 'snoring', 'drinking_sipping',
         'door_wood_knock', 'mouse_click', 'keyboard_typing', 'door_wood_creaks', 'can_opening', 'washing_machine', 'vacuum_cleaner', 'clock_alarm', 'clock_tick', 'glass_breaking',
         'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine', 'train', 'church_bells', 'airplane', 'fireworks', 'hand_saw'
         ]

def metrics(reduced_matrix, names):

    results_matrix = []

    for name in names:
        tv = total_variance(df, reduced_matrix, name)
        gv = generalized_variance(df, reduced_matrix, name)
        avg_pdist = avg_pairwise_distance(df, reduced_matrix, name)

        results_matrix.append([name, tv, gv, avg_pdist])
        metrics_matrix = np.array(results_matrix)

    return metrics_matrix


# Call the function
metrics_matrix = metrics(reduced_matrix, names)

# Print the matrix
print("Metrics Matrix:")
print(metrics_matrix)

metrics_matrix.shape



saved_metrics = pd.DataFrame(metrics_matrix)
saved_metrics.to_csv('metrics_matrix.csv', index=False)

from google.colab import files

# Provide the file name you want to download
files.download('metrics_matrix.csv')

!pip install umap-learn
import seaborn as sns

import umap

# Calculate UMAP embeddings for all the features
reducer = umap.UMAP(random_state=42)
embedding = reducer.fit_transform(reduced_matrix)


# Create a scatter plot of the UMAP embeddings with different colors for each class
sns.set(style='white', context='notebook', rc={'figure.figsize': (7, 5)})
palette = sns.color_palette("husl", as_cmap=True)

class_names = ["train", "wind"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "train"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "wind"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["wind", "train"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")


print('\n')
class_name = "train"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = "wind"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = ["wind", "train"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

print('\n')
class_name = "train"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "wind"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["wind", "train"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["rain", "thunderstorm"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "rain"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "thunderstorm"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["rain", "thunderstorm"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")


print('\n')
class_name = "rain"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = "thunderstorm"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = ["rain", "thunderstorm"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

print('\n')
class_name = "rain"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "thunderstorm"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["rain", "thunderstorm"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["airplane", "coughing"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "airplane"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "coughing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["airplane", "coughing"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

print('\n')
class_name = "airplane"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = "coughing"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = ["airplane", "coughing"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

print('\n')
class_name = "airplane"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "coughing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["airplane", "coughing"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["cow", "keyboard_typing"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "cow"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "keyboard_typing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["cow", "keyboard_typing"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

print('\n')
class_name = "cow"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = "keyboard_typing"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = ["cow", "keyboard_typing"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

print('\n')
class_name = "cow"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "keyboard_typing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["cow", "keyboard_typing"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["laughing", "clock_tick"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "laughing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "clock_tick"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["laughing", "clock_tick"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

print('\n')
class_name = "laughing"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = "clock_tick"
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

class_name = ["laughing", "clock_tick"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(f"avg_pairwise_distance for class/es '{class_name}': {result}")

print('\n')
class_name = "laughing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "clock_tick"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["laughing", "clock_tick"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")