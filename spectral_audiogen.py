# -*- coding: utf-8 -*-
"""Spectral_audioGen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZsJSdOWKbC530ARQ94_UobBIF5ItR5CK
"""

import pandas as pd
import csv
import librosa
import librosa.display
import numpy as np
import requests
import scipy
import matplotlib.pyplot as plt

# Define the URL of the CSV file

csv_url = 'https://raw.githubusercontent.com/azadehn/AudioGen/main/audioGen_dataset.csv'

# Read the CSV file from the provided URL
df = pd.read_csv(csv_url)

#print(df.head())

#df = pd.read_csv(csv_url, error_bad_lines=False)
#airplane_df = df[df['category'] == 'airplane']

# Print the first 5 rows of the DataFrame
#print(airplane_df.head())

from io import BytesIO

def load_audio_data(row):
    # Construct the raw content URL for the audio file
    audio_file_url = f'https://github.com/azadehn/AudioGen/blob/main/audio/{row["filename"]}'

    # Download the audio file
    response = requests.get(audio_file_url)

    if response.status_code == 200:
        # Create a BytesIO object from the response content
        audio_data = BytesIO(response.content)

        # Load the audio from the BytesIO object
        y, sr = librosa.load(audio_data, sr=None)
        return y, sr

import os
import zipfile


def load_audio_data(row):
    # Local file paths for the zip files
    zip_file_paths = [
        '/content/1_1000.zip',
        '/content/1001_2000.zip'
    ]

    # Create a temporary directory to extract audio files
    temp_dir = '/content/temp_audio'
    os.makedirs(temp_dir, exist_ok=True)

    audio_files = []  # To store loaded audio data

    for zip_path in zip_file_paths:
        # Extract the zip file
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)

        # Get the filename from the row (assuming it matches the audio file in the zip)
    filename = row["filename"]

        # Load the audio file from the extracted location
    audio_path = os.path.join(temp_dir, filename)
    y, sr = librosa.load(audio_path, sr=None)


    return y, sr  # Return loaded audio data

"""Comprehensive matrix"""

def comprehensive_matrix(df):
    # Initialize empty list to store feature vectors
    features = []

    for index, row in df.iterrows():
        y, sr = load_audio_data(row)

        # Extract MFCC features
        mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr)

        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_variance = np.var(mfcc, axis=1)
        mfcc_delta = librosa.feature.delta(mfcc)
        delta_mean = np.mean(mfcc_delta, axis=1)
        mfcc_delta_delta = librosa.feature.delta(mfcc, order=2)
        delta_delta_mean = np.mean(mfcc_delta_delta, axis=1)

        # Append the results to the respective lists
        feature_vector = np.concatenate((mfcc_mean, mfcc_variance, delta_mean, delta_delta_mean))

        features.append(feature_vector)

    # Convert the lists of feature vectors to a feature matrix
    comprehensive_matrix = np.array(features)

    return comprehensive_matrix




# Call the function with the DataFrame as an argument
comprehensive_matrix = comprehensive_matrix(df)

# Print the matrix
print("Comprehensive Matrix:")
print(comprehensive_matrix)

comprehensive_matrix.shape

"""Save and download the matrix"""

saved_matrix = pd.DataFrame(comprehensive_matrix)
saved_matrix.to_csv('comprehensive_matrix.csv', index=False)

from google.colab import files

# Provide the file name you want to download
files.download('comprehensive_matrix.csv')

"""Read the matrix"""

comprehensive_matrix = pd.read_csv('comprehensive_matrix.csv').values

!pip install scikit-learn
from sklearn.decomposition import PCA

"""Scree plot"""

import matplotlib.pyplot as plt


def scree_plot(comprehensive_matrix, num_components=None):

    # Perform PCA
    pca = PCA()
    pca.fit(comprehensive_matrix)

    explained_variace = np.cumsum(pca.explained_variance_ratio_)

    if num_components is not None:
        explained_variace = explained_variace[:num_components]

    # Plot the scree plot
    plt.plot(range(1, len(explained_variace) + 1), explained_variace, marker='o', linestyle='-')
    plt.xlabel('Principal Component Number')
    plt.ylabel('Eigenvalue')
    plt.title('Scree Plot')
    plt.grid()
    plt.show()


# To plot all components:
scree_plot(comprehensive_matrix)

"""PCA"""

def pca(comprehensive_matrix, num_components=None):

    # Initialize PCA
    pca = PCA(n_components=num_components,whiten = True)

    # Fit the PCA model to the data and transform the data
    reduced_features = pca.fit_transform(comprehensive_matrix)

    return reduced_features


# Call the function to run PCA on comprehensive matrix
reduced_matrix = pca(comprehensive_matrix, num_components=10)

# Print the matrix
print("Reduced Matrix:")
print(reduced_matrix)

reduced_matrix.shape

"""Total variance"""

def total_variance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    tv = np.trace(np.cov(reduced_matrix[df['category'].isin(class_names)].T))

    return tv

class_name = ["dog", "rain"]
result = total_variance(df, reduced_matrix, class_name)
print(result)

"""Generalized variance"""

def generalized_variance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    gv = np.linalg.det(np.cov(reduced_matrix[df['category'].isin(class_names)].T))

    return gv

class_name = ["dog", "rain"]
result = generalized_variance(df, reduced_matrix, class_name)
print(result)

"""avg_pairwise distance"""

def avg_pairwise_distance(df, reduced_matrix, class_names):

    if not isinstance(class_names, list):
        class_names = [class_names]

    pdist = scipy.spatial.distance.pdist(reduced_matrix[df['category'].isin(class_names)])
    avg_pdist = np.mean(pdist)

    return avg_pdist

class_name = ["dog", "rain"]
result = avg_pairwise_distance(df, reduced_matrix, class_name)
print(result)

import scipy.spatial.distance

names = ['dog', 'rooster', 'pig', 'cow', 'frog', 'cat', 'hen', 'insects', 'sheep', 'crow',
         'rain', 'sea_waves', 'crackling_fire', 'crickets', 'chirping_birds', 'water_drops', 'wind', 'pouring_water', 'toilet_flush', 'thunderstorm',
         'crying_baby', 'sneezing', 'clapping', 'breathing', 'coughing', 'footsteps', 'laughing', 'brushing_teeth', 'snoring', 'drinking_sipping',
         'door_wood_knock', 'mouse_click', 'keyboard_typing', 'door_wood_creaks', 'can_opening', 'washing_machine', 'vacuum_cleaner', 'clock_alarm', 'clock_tick', 'glass_breaking',
         'helicopter', 'chainsaw', 'siren', 'car_horn', 'engine', 'train', 'church_bells', 'airplane', 'fireworks', 'hand_saw'
         ]

def metrics(reduced_matrix, names):

    results_matrix = []

    for name in names:
        tv = total_variance(df, reduced_matrix, name)
        gv = generalized_variance(df, reduced_matrix, name)
        avg_pdist = avg_pairwise_distance(df, reduced_matrix, name)

        results_matrix.append([name, tv, gv, avg_pdist])
        metrics_matrix = np.array(results_matrix)

    return metrics_matrix


# Call the function
metrics_matrix = metrics(reduced_matrix, names)

# Print the matrix
print("Metrics Matrix:")
print(metrics_matrix)

metrics_matrix.shape



saved_metrics = pd.DataFrame(metrics_matrix)
saved_metrics.to_csv('metrics_matrix.csv', index=False)

from google.colab import files

# Provide the file name you want to download
files.download('metrics_matrix.csv')

"""UMAP"""

!pip install umap-learn
import seaborn as sns

import umap

# Calculate UMAP embeddings for all the features
reducer = umap.UMAP(random_state=42)
embedding = reducer.fit_transform(reduced_matrix)


# Create a scatter plot of the UMAP embeddings with different colors for each class
sns.set(style='white', context='notebook', rc={'figure.figsize': (7, 5)})
palette = sns.color_palette("husl", as_cmap=True)

"""Examples"""

class_names = ["train", "wind"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "train"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "wind"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["wind", "train"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")



print('\n')
class_name = "train"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "wind"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["wind", "train"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["rain", "thunderstorm"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "rain"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "thunderstorm"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["rain", "thunderstorm"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")



print('\n')
class_name = "rain"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "thunderstorm"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["rain", "thunderstorm"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["airplane", "coughing"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "airplane"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "coughing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["airplane", "coughing"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")



print('\n')
class_name = "airplane"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "coughing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["airplane", "coughing"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["cow", "keyboard_typing"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "cow"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "keyboard_typing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["cow", "keyboard_typing"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")



print('\n')
class_name = "cow"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "keyboard_typing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["cow", "keyboard_typing"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_names = ["laughing", "clock_tick"]
# Filter UMAP embeddings for each class
for class_name in class_names:
    umap_embeddings_class = embedding[df['category'] == class_name]
    sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label=class_name)

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()


class_name = "laughing"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = "clock_tick"
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")

class_name = ["laughing", "clock_tick"]
result = total_variance(df, reduced_matrix, class_name)
print(f"total variance for class/es '{class_name}': {result}")



print('\n')
class_name = "laughing"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = "clock_tick"
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")

class_name = ["laughing", "clock_tick"]
result = generalized_variance(df, reduced_matrix, class_name)
print(f"generalized_variance for class/es '{class_name}': {result}")